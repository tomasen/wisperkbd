# WisperKbd

macOS Input Method (IME) that uses WhisperKit for local speech-to-text. Recognized speech is inserted directly at the cursor in any app — no copy-paste. Normal typing works as usual when not recording.

## Architecture

```
WisperKbd.app (IMKit input method)
├── main.swift                — Entry point, WisperApplication (NSApplication subclass)
├── AppDelegate.swift         — IMKServer initialization
├── InputController.swift     — IMKInputController subclass, handles input lifecycle + UX + menus
├── AudioCaptureManager.swift — AVAudioEngine mic → 16kHz mono Float32, full session buffer
├── WhisperManager.swift      — WhisperKit pipeline wrapper, state machine, settings persistence
└── Resources/
    ├── en.lproj/InfoPlist.strings — Localized display names for input source
    ├── icon.tiff              — Menu bar icon (template, adapts to light/dark)
    └── icon_recording.tiff    — Recording state icon (with red dot)
```

## How It Works

1. App registers as a macOS input method via IMKit (Input Method Kit)
2. User enables it in System Settings > Keyboard > Input Sources
3. When activated, a hint appears: "[Hold right Option to speak]"
4. **Normal typing passes through** — all key events are forwarded when not recording
5. User holds **right Option key** → status shows "[Listening...]"
6. Audio is captured and accumulated in a full session buffer (up to 30s)
7. Every ~1.5s, the FULL session buffer is re-transcribed by Whisper (preserving context)
8. Partial results appear as underlined marked text at the cursor
9. On key release → "[Processing...]" shown → final transcription committed via `insertText()`

## Status Indicators (shown as marked text)

- `[Downloading speech model...]` — First launch, model being downloaded
- `[Loading speech model...]` — Model loaded into memory
- `[Ready — hold right Option to speak]` — Model ready
- `[Hold right Option to speak]` — Hint on activation
- `[Listening...]` — Recording in progress
- `[Processing...]` — Final transcription after recording stops
- `[Cannot record: ...]` — Error state (model not ready, etc.)

## Settings (via menu bar dropdown)

- **Model selection**: Tiny (~75MB), Base (~140MB), Small (~460MB), Large (~3GB)
  - Persisted in UserDefaults (`WisperKbd_SelectedModel`)
  - Switching models triggers re-download + re-initialization
- **Language selection**: Auto-detect, English, Chinese, Japanese, Korean, German, French, Spanish, Portuguese, Russian, Arabic, Italian
  - Persisted in UserDefaults (`WisperKbd_SelectedLanguage`)
  - `nil` = auto-detect (uses multilingual model)

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Speech engine | WhisperKit (Apple Silicon optimized, CoreML) |
| Default model | openai_whisper-small (multilingual, configurable) |
| Audio capture | AVAudioEngine (resampled to 16kHz mono Float32) |
| Text insertion | IMKit (IMKInputController → IMKTextInput) |
| Language | Swift 5.9 |
| Build system | Xcode project generated by xcodegen |
| Min macOS | 14.0 (Sonoma) |

## Project Structure

```
wisperkbd/
├── CLAUDE.md                 — This file
├── Makefile                  — Build, install, clean, release, dist, notarize
├── project.yml               — xcodegen project spec
├── scripts/
│   └── generate_icon.swift   — Generates icon.tiff + icon_recording.tiff from SF Symbols
├── WisperKbd/
│   ├── Info.plist            — IMKit config (connection name, input modes, display name)
│   ├── WisperKbd.entitlements — Sandbox + mic + Mach port + network entitlements
│   ├── main.swift            — App entry point
│   ├── AppDelegate.swift     — IMKServer setup
│   ├── InputController.swift — Core input handling + UX states + settings menus
│   ├── AudioCaptureManager.swift — Mic capture + resampling + session buffer
│   ├── WhisperManager.swift  — WhisperKit integration + state machine + settings
│   └── Resources/
│       ├── en.lproj/InfoPlist.strings — Display name localization
│       ├── icon.tiff          — Menu bar icon
│       └── icon_recording.tiff — Recording state icon
└── WisperKbd.xcodeproj/     — Generated by xcodegen (do not edit directly)
```

## Key Configuration

- **Bundle ID**: `com.tomasen.inputmethod.WisperKbd` (must contain `.inputmethod.`)
- **Mach connection**: `com.tomasen.inputmethod.WisperKbd_Connection`
- **Controller class**: `WisperKbd.InputController` (module-qualified for Swift)
- **Display name**: Set in `Info.plist` (`InputMethodServerName`) and `InfoPlist.strings`
- **Install location**: `~/Library/Input Methods/WisperKbd.app`

## Build & Install

```bash
# One-command build + install (recommended)
make install

# Or step by step:
make generate   # Generate Xcode project from project.yml
make build      # Build the project
make install    # Kill old instance + build + install
make run        # Build + install + launch
make clean      # Clean build artifacts
make uninstall  # Remove from Input Methods
make status     # Show install/run status

# First time: enable in System Settings > Keyboard > Input Sources > Edit > + > WisperKbd
# May need to log out/in if it doesn't appear
```

## Distribution

**Cannot use Mac App Store** (IMKit requires background-only app, Mach port exceptions, ~/Library/Input Methods install path).

Distribution options: direct download, Homebrew Cask, GitHub Releases.

```bash
make release    # Build optimized release version
make dist       # Create ZIP for distribution
make notarize   # Notarize (needs APPLE_ID, TEAM_ID, APP_PASSWORD env vars)
```

## Permissions Required

- **Microphone**: Prompted on first recording attempt (orange dot appears in menu bar)
- **Input Monitoring**: Required for all third-party input methods (System Settings > Privacy)
- **Sandbox exceptions**: Mach port registration for IMKServer IPC
- **Network**: For initial model download by WhisperKit

## Debugging

- Use `NSLog()` not `print()` — IMKit apps don't have stdout connected
- View logs in Console.app, filter by "WisperKbd"
- After rebuilding, must `killall WisperKbd` for macOS to load new binary
- If input method doesn't appear, try logging out and back in
- WhisperManager state transitions are logged
- `make status` shows install/run state

## Hotkeys

- **Right Option (hold)**: Start/stop recording
- **Escape (while recording)**: Cancel recording, discard text
- **All other keys**: Pass through normally (regular typing works)

## Audio Pipeline

- Mic → AVAudioEngine tap (hardware rate, e.g., 48kHz)
- → AVAudioConverter → 16kHz mono Float32
- → Session buffer (accumulates full recording, max 30s, trims from front)
- → Every ~1.5s, full buffer sent to WhisperKit for re-transcription
- → On stop, final full-buffer transcription → committed text

## WhisperManager States

`notLoaded` → `downloading` → `loading` → `ready`
                                          ↘ `failed(error)` → retry on next use

Model switch: `ready` → `notLoaded` → `downloading` → `loading` → `ready`

## Dependencies

- **WhisperKit** >= 0.9.0 (SPM, from https://github.com/argmaxinc/WhisperKit.git)
- **xcodegen** (Homebrew: `brew install xcodegen`)

## Known Limitations

- Cannot be distributed via Mac App Store (IMKit restriction)
- Secure text fields (passwords) may block third-party IMEs
- First launch requires model download (size depends on selected model)
- Max continuous recording ~30s before audio buffer trims from front
- IMKit has no public API to dynamically change menu bar icon at runtime
- No iOS version possible (Apple blocks mic access in keyboard extensions)
